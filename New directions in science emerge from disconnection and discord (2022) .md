# New directions in science emerge from disconnection and discord (2022)

### 1. 研究对象

-   **研究领域与背景**
    -   本研究属于科学计量学和社会学领域，旨在探讨科学思想的演化和接受过程。
    -   研究背景指出，科学界长期以来过度依赖引文影响力（如被引次数）作为评价科研成果的主要标准。这种对单一指标的固化导致了科研人员倾向于选择短期内能快速获得引用的“时髦”领域，造成了科学前沿的“拥堵”，并降低了短期影响力与长期价值之间的关联。因此，学术界迫切需要超越流行度的替代性评价指标，以揭示科研工作更多维度的特征，例如识别那些真正开辟新方向的“创造性破坏”工作。

-   **具体研究对象或数据集**
    -   **核心数据集**：研究使用了微软学术图谱（Microsoft Academic Graph, MAG），该数据集包含了从1800年到2020年发表的8786万篇期刊文章及其超过10亿条引文记录。
    -   **分析子集**：分析的核心对象是数据集中3543万篇同时拥有参考文献和后续引文的文章。
    -   **时间队列（Cohorts）**：为了分析动态变化，研究选取了四个特定年份发表的论文队列进行重点分析，分别是1970年（87,475篇论文）、1980年（176,826篇论文）、1990年（318,914篇论文）和2000年（591,653篇论文）。
    -   **知识空间构建数据**：为了构建和可视化知识空间，研究使用了1970年（涉及2429种期刊）和2000年（涉及8009种期刊）的期刊共被引数据。

### 2. 研究方法

-   **使用的理论框架与算法**
    -   **理论框架**：本研究整合并深入分析了两个近期提出的重要科学计量学概念：
        1.  **非典型性（Atypicality）**：衡量一篇论文是否通过新颖、罕见的组合方式来借鉴先前的研究。
        2.  **颠覆性（Disruption）**：衡量一篇论文在多大程度上开创了一个新的研究方向，以至于后续研究在引用它时，会“绕过”它所引用的早期基础文献。
    -   **核心算法与技术**：
        1.  **z-score统计**：用于量化一篇论文参考文献中期刊配对的“典型性”或“非典型性”。
        2.  **D-score计算**：用于量化一篇论文的“颠覆性”或“发展性”。
        3.  **神经网络嵌入（Neural Network Embedding）**：本文提出的一项核心方法创新，使用类似`word2vec`的Skip-gram模型将期刊嵌入到低维向量空间中，从而将“非典型性”重新定义为知识空间中的“距离”。
        4.  **t-SNE降维算法**：用于将高维的期刊向量投影到二维平面上，以便可视化知识空间的结构和演变。

-   **模型 / 技术详解**
    -   **非典型性（z-score）**
        -   **架构**：基于Uzzi等人提出的方法，通过比较期刊对的“实际共被引频率”与“期望共被引频率”来计算z-score。
        -   **输入**：一篇论文的参考文献列表。
        -   **流程**：对论文参考文献中的每一对期刊(i, j)，计算其z-score。期望频率通过随机置换引文关系来计算，同时保持每篇论文的参考文献数量和年份分布不变。
        -   **输出**：一篇论文会得到一个z-score的分布。研究主要使用两个指标来表征这篇论文的非典型性：分布的**中位数 (z_median)** 代表平均典型性，分布的**第10百分位数 (z_min)** 代表最大非典型性。
    -   **颠覆性（D-score）**
        -   **架构**：基于Wu, Wang & Evans提出的方法，通过分析后续引文模式来衡量。
        -   **输入**：一篇核心论文（focal paper）及其参考文献，以及所有引用这篇核心论文的后续论文。
        -   **流程**：将引用核心论文的后续文献分为两类：一类只引用了核心论文；另一类同时引用了核心论文及其参考文献。D-score是这两类文献所占比例的差值。
        -   **输出**：一个介于-1到1之间的D-score。D > 0 表示颠覆性，意味着后续研究认可其开创性而忽略其基础；D < 0 表示发展性/巩固性；D = 0 表示平衡。
    -   **期刊嵌入（Journal Embedding）**
        -   **架构**：采用`word2vec`的Skip-gram算法，将期刊视为“单词”，将一篇论文的参考文献列表视为这些“单词”的“上下文”。
        -   **输入**：特定年份的期刊共被引网络。
        -   **训练流程**：模型通过一个带有一个隐藏层的神经网络进行优化，学习出一个能最好地保留期刊间共现关系的向量表示。目标是让在相似上下文（即经常被一同引用）中出现的期刊在向量空间中的位置更近。
        -   **输出**：每个期刊的一个k维向量。两个期刊向量的“内积”被证明与它们的逐点互信息（PMI）成正比，而PMI在形式上等同于z-score。这使得“非典型性”可以被高效地、动态地计算为知识空间中的距离。
        -   **优势**：该方法将离散的共引关系转化为连续的知识空间，不仅计算上更高效，而且能够捕捉和可视化整个科学知识版图的动态演变。

-   **关键公式或模型（如有）**
    -   **z-score公式**:
        $$z_{ij}=(obs_{ij}-exp_{ij})/\sigma_{ij}$$
        其中，$obs_{ij}$ 是期刊 i 和 j 被共引的观测频率，$exp_{ij}$ 是期望频率，$\sigma_{ij}$ 是标准差。
    -   **D-score公式**:
        $$D=p_{i}-p_{j}=\frac{n_{i}-n_{j}}{n_{i}+n_{j}+n_{k}}$$
        其中，$n_i$ 是只引用核心论文的后续论文数，$n_j$ 是同时引用核心论文及其参考文献的后续论文数，$n_k$ 是只引用参考文献的后续论文数。
    -   **PMI与z-score的关系**:
        $$MI_{ij}=log_{2}(\frac{P_{ij}}{P_{i}\times P_{j}})=log_{2}(obs_{ij})-log_{2}(exp_{ij})$$
        这表明PMI在形式上与z-score类似，都是比较观测值与期望值。
    -   **嵌入向量与PMI的关系**:
        $$emb_{in-i}\cdot emb_{out-j}=PMI_{ij}-log_{2}Neg$$
        这揭示了两个嵌入向量的内积直接关联到它们的PMI，从而将z-score与向量空间距离联系起来。

### 3. 研究内容

-   **主要研究问题**
    1.  一篇新颖的（非典型的）论文在多大程度上能够成功开辟一个新的科学方向并颠覆现有科学？即，新颖的“输入”是否能预测颠覆性的“输出”？
    2.  如果新颖的论文确实能颠覆科学，这个过程需要多长时间？其时间动态是怎样的？
    3.  科学新颖性的“版图”本身是如何演变的？昨天的“非典型”是如何成为今天的“常规”，并为明天的突破设定新背景的？

-   **论文各章节的核心工作**
    -   **第一、二章（引言与文献综述）**：指出现有评价体系的弊端，引入“非典型性”和“颠覆性”作为更有价值的度量。详细阐述了这两个概念的理论基础，以及与科学界“睡美人”现象（即论文被延迟认可）的潜在联系，并正式提出了三个核心研究问题。
    -   **第三、四章（数据与方法）**：介绍了使用的大规模MAG数据集，并详细说明了计算z-score、D-score以及将z-score重构为知识空间距离的期刊嵌入方法的具体步骤和公式。
    -   **第五章（研究发现）**：这是论文的实证核心，分为三个部分：
        1.  **5.1节** 证明了新颖的论文更有可能颠覆现有文献。通过对比沃森和克里克的DNA论文（颠覆性）与巴尔的摩的RNA论文（发展性）两个经典案例，并结合大规模统计数据，揭示了非典型性与颠覆性之间的正向关联。
        2.  **5.2节** 探讨了颠覆过程的时间动态。研究发现，非典型论文的颠覆性效应是缓慢的，其影响力（特别是颠覆性引文）和D-score需要很长时间才能累积和稳定，表现出明显的“睡美人”特征。
        3.  **5.3节** 首次展示了通过期刊嵌入构建的动态“知识空间”。验证了该方法（空间距离与z-score强相关），并可视化了从1970年到2000年科学版图的巨大变迁，如子领域的形成和跨学科领域的融合。
    -   **第六章（讨论）**：总结了研究发现，强调了区分不同科学贡献（发展型 vs. 颠覆型）的重要性。并从科学政策的角度出发，呼吁建立能够衡量和激励长期、变革性创新的评价体系，以克服当前对短期影响力的过度关注。

### 4. 研究结论

-   **重要发现与定量/定性结果**
    -   **非典型性预测颠覆性**：非典型的论文颠覆科学的可能性是常规论文的近两倍（61% vs 36%）。典型性（$z_{median}$）与颠覆性（D-score）之间存在显著的负相关关系（Pearson r = -0.05, p < 0.001），这意味着越非典型的论文越倾向于具有颠覆性。
    -   **颠覆的缓慢过程**：非典型论文的颠覆过程非常缓慢，其D-score通常需要十年或更长时间才能趋于稳定。这与发展性论文的D-score在五年内就迅速收敛形成鲜明对比。
    -   **“睡美人”现象的机制**：非典型论文更有可能成为“睡美人”，它们的引文影响力（特别是颠覆性引文）和睡美人指数（SBI）会在长时间延迟后持续增长。非典型性与SBI在对数尺度上呈正相关（Pearson r = 0.08, p < 0.001）。
    -   **知识空间的重构与验证**：成功将“非典型性”重构为嵌入空间中的距离。期刊嵌入向量的内积与原始的z-score之间存在极强的相关性（Pearson r = 0.74, p < 0.001），证明了该计算框架的有效性。
    -   **科学版图的演化**：通过可视化1970年和2000年的知识空间，揭示了科学结构的动态变化：各领域内部逐渐形成更密集的子领域，同时跨学科研究的重要性日益增加，例如社会科学和计算机科学之间的“距离”在30年间显著缩小。

-   **对学术或实际应用的意义**
    -   **理论意义**：本研究为理解科学创新机制提供了新的实证证据和分析工具。它揭示了“非典型”组合作为创新源头，通过漫长的“颠覆”过程最终改变科学格局的深层机制，并将“睡美人”现象与论文的内在知识结构联系起来。
    -   **实际应用**：研究结果对科学政策制定者、科研资助机构和大学管理者具有重要启示。它表明，过度依赖短期、高引用的评价指标可能会扼杀真正具有变革潜力的创新。论文呼吁设计和实施能够识别并奖励那些通往长远成功道路上的“有价值的失败”和非典型探索的评价体系，从而推动科学实现可持续的、突破性的发展。

### 5. 创新点、研究问题与出发点

-   **创新点逐条列出**
    1.  **整合两大前沿指标**：首次系统地将“非典型性”（Atypicality）和“颠覆性”（Disruption）这两个独立的、前沿的科学计量学指标联系起来，并揭示了它们之间存在一种强烈的、但有时间延迟的因果关系。
    2.  **提出动态知识空间模型**：创建了第一个将“非典型性”重构为在潜在知识空间中“距离”的计算模型。该模型使用神经网络嵌入技术，使非典型性的度量变得动态、高效，并能够可视化整个科学知识版图的演变。
    3.  **揭示颠覆的时间动态**：深入分析了颠覆性指标（D-score）随时间演变的模式，证明了颠覆是一个长期过程，并首次从量化角度将其与“睡美人”现象的机制联系起来，解释了为何新颖的思想需要更长时间才能被科学界接受。
    4.  **可视化科学前沿的变迁**：通过对比1970年和2000年的期刊嵌入空间，直观地展示了科学领域内部结构（子领域形成）和领域间关系（跨学科融合）的宏观演变。

-   **作者提出的核心问题**
    -   新的、革命性的科学思想是如何被评价并最终被纳入科学正典的？具体而言，新颖的知识组合（非典型性）与开创新方向的成果（颠覆性）之间存在何种关系？这种关系是如何随时间展开的？以及，判断“新颖性”的标准本身又是如何随科学发展而演变的？

-   **研究动机与假设**
    -   **动机**：当前科学评价体系过度依赖“引文影响力”，这扭曲了科研激励，阻碍了根本性的创新。因此，需要开发和理解能够捕捉科学贡献不同维度的替代性指标。
    -   **假设**：
        1.  颠覆性的科学成果更有可能源于非典型的知识组合，而非建立在已有共识的基础上。
        2.  由于新颖的思想挑战了传统认知，它们被科学界接受和认可的过程是缓慢的，因此，非典型/颠覆性的论文更有可能成为具有延迟影响力的“睡美人”。
        3.  科学知识的结构不是一成不变的，可以通过嵌入模型来捕捉其动态演变，从而理解“新颖性”的相对性和历史性。

### 6. 创新点与出发点的验证与实现

-   **实验/仿真/原型设计流程**
    1.  **数据处理与指标计算**：
        -   使用微软学术图谱（MAG）数据，为超过3500万篇论文计算其非典型性（$z_{median}$）和颠覆性（D-score）。
        -   筛选出1970、1980、1990、2000四个年份的论文队列作为核心分析样本。
    2.  **非典型性与颠覆性的关联分析**：
        -   首先，对全量数据计算$z_{median}$和D-score的皮尔逊相关系数，进行初步的宏观验证。
        -   然后，选取1970年队列中颠覆性最强（D-score排名前5%）和发展性最强（D-score排名后5%）的论文，对比它们z-score的累积分布，并用K-S检验其差异的显著性。
        -   通过沃森和克里克的DNA论文与巴尔的摩的RNA论文两个经典案例，进行深入的定性与定量对比分析。
    3.  **时间动态分析**：
        -   追踪上述两个案例论文的D-score从发表后数十年的演变曲线，并分解其颠覆性引文和发展性引文的增长情况。
        -   将1970年队列的论文按最终D-score分为10组，绘制每组论文的平均D-score随时间变化的曲线，以确定其稳定时间。
        -   将四个年代队列的论文按非典型性分为最高10%和最低10%两组，对比这两组论文的颠覆性/发展性引文随时间的累积差异。
        -   将1970年队列论文按非典型性分为10组，计算并绘制每组论文的睡美人指数（SBI）随时间演变的曲线，以验证非典型性与延迟认可的关系。
    4.  **知识空间构建与验证**：
        -   选取1970年和2000年的期刊共被引数据，使用`word2vec`的Skip-gram算法分别训练两个期刊嵌入模型，得到每个期刊的50维向量。
        -   使用t-SNE算法将50维向量降至2维，并根据期刊所属领域进行着色，可视化知识空间。
        -   为了验证该方法的有效性，计算期刊向量对的内积与它们对应的z-score之间的皮尔逊相关系数。

-   **数据集、参数、评价指标**
    -   **数据集**：微软学术图谱（MAG），并从中划分出1970, 1980, 1990, 2000四个队列。
    -   **参数**：期刊嵌入训练参数：向量维度=50，负采样大小=5，窗口大小=10。
    -   **评价指标**：
        -   **核心指标**：非典型性 ($z_{median}, z_{min}$)、颠覆性 (D-score)。
        -   **辅助/验证指标**：引文数、睡美人指数 (SBI)、皮尔逊相关系数、K-S检验统计量。

-   **结果对比与可视化描述**
    -   **图1**：概念阐释与初步验证。图1c清晰地显示，高颠覆性论文的z-score分布（更非典型）与高发展性论文的分布（更典型）有显著差异。图1d则复现并对比了Uzzi的发现，即高影响力论文倾向于混合常规与非常规的参考文献。
    -   **图2**：时间动态的可视化。图2a/b通过案例展示了颠覆性（DNA论文）与发展性（RNA论文）D-score随时间演变的巨大差异。图2c/d显示，对于非典型论文，颠覆性引文的比例随时间放大；而对于常规论文，发展性引文的比例放大。图2e量化了D-score约需10年才能稳定。图2f则直观地表明，高非典型性论文的SBI在延迟十年后仍在持续增长。
    -   **图3**：知识空间的演化。通过对比1970年与2000年的期刊嵌入空间图，生动地展示了科学领域从相对分散到形成紧密子领域，以及跨学科融合（如计算机科学与社会科学靠近）的宏大历史进程。
    -   **图4**：总结性的概念图。清晰地描绘了本研究的核心机制：常规的知识输入 ($z>0$) 倾向于产生发展性的成果 ($D<0$)；而非典型的知识输入 ($z<0$) 则倾向于产生颠覆性的成果 ($D>0$)。

-   **作者如何证明方法有效性**
    作者通过一个多层次、相互印证的论证体系来确保其结论的可靠性：
    1.  **大规模统计分析**：在数千万篇论文的尺度上，用统计相关性证明了非典型性与颠覆性的宏观联系。
    2.  **经典案例深度剖析**：选取科学史上广为人知且性质明确的发现（DNA vs. RNA）作为范例，使其复杂的量化指标变得直观易懂，增强了结论的说服力。
    3.  **时间序列分析**：通过追踪各项指标随时间的变化，揭示了现象背后的动态过程，而不仅仅是静态的关联，从而为因果推断提供了更强的依据。
    4.  **新方法的交叉验证**：对自己提出的新方法（期刊嵌入），通过与原有方法（z-score）进行相关性检验，以及通过可视化结果的领域聚集效应进行“表面效度”检验，证明了其有效性和合理性。
    5.  **跨年代队列的一致性检验**：在多个时间点（1970-2000）重复关键分析，证明了所发现的规律并非某个特定时代的偶然现象，而是具有普遍性的模式。