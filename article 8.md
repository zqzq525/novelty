# Artificial intelligence policy frameworks in China, the European Union and the United States: An analysis based on structure topic model (2025)

### 1. 研究目标 · 内容 · 问题 · 出发点

- **研究领域与背景、具体对象 / 数据集**
    - **研究领域与背景**：人工智能（AI）作为一把双刃剑，既能驱动经济增长、促进社会发展，也带来了算法偏见、隐私侵犯、安全漏洞等伦理和社会挑战。全球各国纷纷制定政策，旨在促进AI发展的同时规避其风险。然而，目前缺乏一个全面、整合的AI治理政策分析框架。
    - **具体对象 / 数据集**：本研究的核心分析对象是全球AI治理的三个关键行为体——中国、欧盟和美国的AI政策。数据集包含了从2016年至2023年6月收集的139份AI政策文本，其中中国54份，欧盟32份，美国53份。这些文本来源于官方权威数据库（中国的“北大法宝”、欧盟的“EUR-Lex”、美国的“GovInfo”）。

- **论文想解决的核心问题**
    - 中国、欧盟和美国的AI政策框架具体由哪些主题构成？
    - 这些政策主题在各自框架中的重要性（流行度）如何？
    - 三者的政策框架存在哪些差异，并且这些框架是如何随时间演变的？

- **研究动机 / 假设**
    - **研究动机**：现有的AI政策研究大多局限于对单一政策的深度分析、特定国家的政策演进梳理或某个特定方面的探讨，缺乏一个能整合多维度、动态演变且进行跨国比较的综合性框架。
    - **研究假设**：论文假设，由于中国、欧盟和美国在政治体制、文化价值观和经济背景上存在显著差异，其AI政策框架的战略重点和治理模式也会表现出明显的不同。例如，中国可能更侧重于政府主导和技术应用，欧盟侧重于以人为本和伦理规范，而美国则侧重于市场驱动和保持技术领先。

- **工作内容概览**
    - **引言与文献综述**：阐述AI治理的重要性与当前研究的不足，提出研究问题，并回顾AI政策研究和文本分析方法（人工编码 vs. 主题模型）的现状。
    - **理论基础**：界定AI治理概念，并从比较治理的角度分析中国（政府主导的实验主义治理）、欧盟（多层次、以人为本的规范性力量）和美国（市场导向、轻触式监管）的AI治理背景。
    - **数据与方法**：详细介绍139份政策文本的收集过程、文本预处理步骤，并重点阐述为何选择并如何运用结构主题模型（STM）进行分析，包括主题数量（K=13）的确定过程。
    - **研究结果**：展示并解读STM分析得出的13个主要政策主题；通过主题关系网络将其聚类为“研究与应用”、“社会影响”和“政府角色”三大类别；最后，利用协变量分析，动态展示了各主题在三大地区随时间变化的趋势。
    - **讨论与结论**：基于结果，构建了一个全面的AI治理政策框架图，深入探讨了中、美、欧政策的异同及其背后的原因，并总结了研究的理论与实践意义、局限性与未来方向。

### 2. 研究方法（含模型 / 技术详解）

- **理论框架与算法**
    - 本研究采用**结构主题模型（Structural Topic Model, STM）** 作为核心分析方法。STM是一种先进的文本分析技术，是潜在狄利克雷分配（Latent Dirichlet Allocation, LDA）模型的扩展。与LDA假设各主题相互独立且文档的主题分布先验相同不同，STM允许主题之间存在相关性，并能够引入文档级别的元数据（协变量），如文本来源地、发布年份等，来分析这些外部因素如何影响主题的流行度（prevalence）和主题内的词汇使用。

- **关键模型/技术逐一说明：架构、输入输出、训练或推理流程、优势与局限**
    - **模型：结构主题模型 (STM)**
        - **架构**：STM是一个生成式概率模型。它假设每篇文档由多个主题混合而成，每个主题则由一系列词语的概率分布定义。其核心创新在于，模型中的主题流行度先验（prior on topic prevalence）不再是一个固定的狄利克雷分布，而是可以由文档的元数据（协变量）通过一个广义线性模型来预测。
        - **输入**：
            1.  **文档-词条矩阵 (Document-Term Matrix)**：经过预处理后的文本数据，矩阵的行代表文档，列代表词条，单元格是词条在文档中出现的频率。
            2.  **协变量 (Covariates)**：与每篇文档相关联的元数据。在本研究中，协变量是**地区**（中国、欧盟、美国）和**发布年份**（2016-2023）。
        - **训练流程**：
            1.  **预处理**：对原始139份政策文本进行清洗，包括去除数字和标点、转为小写、词干提取、移除停用词和低频词。
            2.  **确定主题数K**：通过迭代测试不同的K值（从3到30），结合数据驱动的统计指标（如排他性、语义一致性、残差和留出似然度）和人工对主题可解释性的判断，最终选定 $K=13$。
            3.  **模型拟合**：使用R语言的“stm”包，将预处理后的文本数据和协变量（地区、年份）输入模型进行训练。模型通过变分期望最大化（variational EM）算法进行参数估计。
        - **输出**：
            1.  13个主题，每个主题由一组高概率的关键词定义。
            2.  每篇文档在13个主题上的概率分布。
            3.  协变量（地区、年份）对每个主题流行度的影响估计值，可用于分析政策重点的跨地区差异和跨时间演变。
        - **优势**：
            - **整合元数据**：能够系统地分析政策内容如何随地区、时间等外部因素变化。
            - **主题相关性**：允许主题间存在关联，更符合政策文本中议题相互关联的现实。
            - **客观与可解释性结合**：将机器学习的客观性与研究者的人工解读相结合，增强了分析的深度和有效性。
        - **局限**：
            - **预处理依赖性**：结果对文本预处理的方式敏感。
            - **主观性**：主题数量K的选择和最终对主题的命名解释仍需依赖研究者的人工判断。

- **重要公式**
    - 论文中没有详细列出STM的数学公式，而是侧重于其方法论的应用和解释，并引用了相关技术文献来说明其数学原理。

### 3. 实验设计与结果（含创新点验证）

- **实验流程**
    1.  **数据收集与筛选**：从中国、欧盟、美国的官方数据库中检索AI相关政策，筛选标准为：必须明确以AI为主题（而非广义的先进技术），且由国家或超国家治理机构发布。最终确定139份2016-2023年的政策文本。
    2.  **文本预处理**：实施标准流程，包括去除数字、标点，转小写，词干提取，移除停用词及出现频率低于5%的词语。最终得到包含139个文档、1834个词条和44,511个词元的语料库。
    3.  **确定最优主题数 (K)**：
        - **第一步（数据驱动）**：对K从3到30的模型进行拟合，并绘制四个关键统计指标（排他性、语义一致性、残差、留出似然度）的变化图。分析发现，当K在10到15之间时，模型在各项指标上达到较好的平衡。
        - **第二步（人工判断）**：研究团队逐一检查K在10到15之间的模型，评估每个主题下的关键词和相关文档的可解释性与意义。经过讨论达成共识，选择 $K=13$ 作为最终主题数，因为它提供了最具洞察力和意义明确的主题集合。
    4.  **模型训练与分析**：使用 $K=13$ 和协变量（地区、年份）训练最终的STM模型。
    5.  **结果解读**：
        - **主题识别**：分析每个主题的关键词和典型政策文本，为13个主题命名。
        - **主题关系与聚类**：分析主题间的相关性（见附录图A1），并结合主题内容进行自下而上的聚类，将13个主题归纳为“研究与应用”、“社会影响”和“政府角色”三个类别。
        - **协变量效应分析**：利用`estimateEffect`函数估计并可视化地区和年份对每个主题流行度的影响，揭示政策重点的差异和演变。

- **数据集、参数、评价指标**
    - **数据集**：139份AI政策文本，构成一个包含1834个独立词条和44,511个词元（token）的语料库。
    - **参数**：主题数 $K=13$。
    - **评价指标**：
        - **模型选择指标**：排他性（Exclusivity）、语义一致性（Semantic Coherence）、残差（Residuals）、留出似然度（Held-out Likelihood）。
        - **结果分析指标**：主题流行度（Topic Prevalence）、主题关键词（Keywords）、主题相关性（Topic Correlation）。

- **创新点如何得到验证，结果对比与可视化描述**
    - 论文的创新点——即利用STM提供一个全面的、比较性的、动态的AI政策框架——通过以下结果得到验证：
        1.  **识别出13个具体且可解释的主题**（如“产业应用”、“政府责任”、“技术标准”等），并用词云图（图3）和关键词表（表2）进行展示，证明了方法的有效性。
        2.  **构建了主题关系网络**（图4），揭示了主题间的内在联系，并成功将其聚类为三大类别，形成了政策框架的基本结构。
        3.  **通过协变量分析验证了核心假设**。图6清晰地展示了不同地区政策重点的差异：
            - **红色线（中国）**：在“产业应用”（Topic 1）、“人才教育”（Topic 7）和“政策试点”（Topic 11）上表现突出，验证了其“研究与应用”导向。
            - **蓝色线（欧盟）**：在“对工作的影响”（Topic 5）、“技术风险”（Topic 6）、“人权”（Topic 9）和“社会合作”（Topic 10）上关注度更高，验证了其“社会影响”导向。
            - **绿色线（美国）**：在“政府责任”（Topic 2）、“研究机构”（Topic 4）和“管理机构”（Topic 12）上占据主导，验证了其“政府角色”导向。
        4.  图6中的时间趋势也验证了**动态演变**的发现，例如所有地区对“制度体系”（Topic 8）、“人权”（Topic 9）和“科学研究”（Topic 13）的关注度都呈上升趋势。

- **主要实验结论与作者解释**
    - **整体来看**，“政府角色”是政策文本中最受关注的类别，而“社会影响”受到的关注最少，这表明当前AI治理可能存在重发展、轻社会考量的倾向。
    - **地区差异**：中国的AI政策优先考虑“研究与应用”类别下的主题；欧盟的政策强调“社会影响”类别；而美国的政策更关注“政府角色”类别。
    - **时间趋势**：“制度体系”、“人权”和“科学研究”这三个主题在所有地区都显示出日益增长的重要性，这预示着全球AI治理可能正从早期的技术驱动转向更加全面、注重伦理和制度建设的范式。

### 4. 研究结论

- **重要发现（定量 / 定性）**
    1.  **构建了三层AI治理框架**：识别出13个核心政策主题，并将其归纳为“研究与应用”、“社会影响”和“政府角色”三大类别。研究发现“政府角色”是受关注最多的类别（占比超40%），而“社会影响”最少（占比约27%）。
    2.  **揭示了三大行为体的战略分野**：中国优先发展“研究与应用”（如产业应用、人才教育）；欧盟以“社会影响”为核心（如人权、技术风险）；美国则聚焦于“政府角色”（如政府职责、管理机构）。
    3.  **发现了全球治理的趋同趋势**：尽管出发点和侧重点不同，但三方都逐渐加强了对“制度体系”、“人权”和“科学研究”的关注，表明全球AI治理正朝着更加规范化、伦理化和科学化的方向发展。
    4.  **提出了一个整合的AI治理框架模型**（图7），该模型不仅包含三大类别，还详细描绘了类别之间（如政府通过政策试验推动研发，社会公众的伦理关切反作用于政府监管）的双向互动关系，形成了一个动态的治理网络。

- **对学术或应用的意义**
    - **学术意义**：
        - 提供了一个全面、整合且动态的AI治理政策分析框架，填补了现有研究的空白。
        - 通过实证数据揭示了不同政治文化背景如何塑造国家AI战略，深化了对全球AI治理格局的理解。
        - 展示了STM作为一种创新的计算社会科学方法在政策文本分析领域的强大应用潜力。
    - **应用意义**：
        - 为各国政策制定者提供了决策参考，强调了在追求技术发展的同时，必须平衡伦理、法规和社会福祉。
        - 强调了建立真正的公众参与机制、构建全面的技术生态系统（包括行业标准）以及加强国际合作的重要性。

### 5. 创新点列表

- **方法论创新**：首次运用结构主题模型（STM）对中国、欧盟、美国三大行为体的AI政策文本进行大规模、系统的量化比较分析。该方法将文本内容与地区、时间等协变量相结合，从而能够动态地揭示政策框架的结构、差异与演变趋势。
- **理论框架创新**：构建了一个全面且动态的AI治理政策框架。该框架不仅识别出“政府角色”、“研究与应用”和“社会影响”三大核心类别及其包含的13个具体主题，更创新性地阐明了这些类别之间的双向互动关系，超越了以往研究的静态和零散视角。
- **实证发现创新**：通过数据驱动的方式，精准量化并对比了中、美、欧在AI治理上的战略侧重点（中国重应用、欧盟重影响、美国重政府角色）。同时，研究还发现了一个重要的趋同现象：三方对制度体系、人权保障和科学研究的关注度均在提升，为理解全球AI治理的未来走向提供了新的实证证据。